{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a37d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import required libraries\n",
    "import tarfile\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "import os\n",
    "\n",
    "# Cell 2: Set up paths and variables\n",
    "# Your deployment package directory (based on your folder structure)\n",
    "deployment_package_dir = '/home/sagemaker-user/keyword-recommendation/sample_deployment/deployment_package'\n",
    "\n",
    "# S3 bucket details\n",
    "bucket_name = 'your-s3-bucket-name'  # Replace with your actual bucket name\n",
    "s3_key = 'models/fin-keyword-model/model.tar.gz'\n",
    "\n",
    "# SageMaker endpoint name\n",
    "endpoint_name = 'fin-keyword-endpoint'\n",
    "\n",
    "# Cell 3: Create the model.tar.gz package\n",
    "print(\"Creating model.tar.gz package...\")\n",
    "\n",
    "# Change to the directory containing deployment_package\n",
    "os.chdir('/home/sagemaker-user/keyword-recommendation/sample_deployment')\n",
    "\n",
    "# Create the model.tar.gz file\n",
    "with tarfile.open('model.tar.gz', 'w:gz') as tar:\n",
    "    # Add the entire deployment_package directory\n",
    "    tar.add('deployment_package', arcname='.')\n",
    "    \n",
    "print(\"Model package created: model.tar.gz\")\n",
    "\n",
    "# Verify the contents\n",
    "with tarfile.open('model.tar.gz', 'r:gz') as tar:\n",
    "    print(\"Contents of model.tar.gz:\")\n",
    "    for member in tar.getmembers():\n",
    "        print(f\"  {member.name}\")\n",
    "\n",
    "# Cell 4: Upload to S3\n",
    "print(\"Uploading model to S3...\")\n",
    "\n",
    "# Initialize S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Upload the model package\n",
    "s3.upload_file('model.tar.gz', bucket_name, s3_key)\n",
    "\n",
    "print(f\"Model uploaded to s3://{bucket_name}/{s3_key}\")\n",
    "\n",
    "# Cell 5: Initialize SageMaker session\n",
    "print(\"Initializing SageMaker session...\")\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "print(f\"Using region: {region}\")\n",
    "print(f\"Using role: {role}\")\n",
    "\n",
    "# Cell 6: Deploy the model\n",
    "print(\"Deploying model to SageMaker...\")\n",
    "\n",
    "# Create the model\n",
    "model = PyTorchModel(\n",
    "    model_data=f's3://{bucket_name}/{s3_key}',\n",
    "    role=role,\n",
    "    framework_version='1.9.0',  # PyTorch version\n",
    "    py_version='py38',         # Python version\n",
    "    entry_point='inference.py',\n",
    "    name='fin-keyword-model',\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Deploy the model\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "\n",
    "print(f\"Endpoint deployed: {predictor.endpoint_name}\")\n",
    "\n",
    "# Cell 7: Test the endpoint\n",
    "print(\"Testing the endpoint...\")\n",
    "\n",
    "# Test data\n",
    "test_data = [\n",
    "    {\n",
    "        \"description\": \"steel pipe 2 inch diameter\",\n",
    "        \"keyword\": \"pipe\"\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"aluminum sheet 5mm thickness\", \n",
    "        \"keyword\": \"sheet\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Make prediction\n",
    "try:\n",
    "    response = predictor.predict(test_data)\n",
    "    print(\"Test successful!\")\n",
    "    print(\"Response:\", response)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", str(e))\n",
    "\n",
    "# Cell 8: Monitor the deployment\n",
    "print(\"Monitoring deployment status...\")\n",
    "\n",
    "# Check endpoint status\n",
    "sm_client = boto3.client('sagemaker')\n",
    "endpoint_status = sm_client.describe_endpoint(\n",
    "    EndpointName=endpoint_name\n",
    ")['EndpointStatus']\n",
    "\n",
    "print(\"Endpoint status:\", endpoint_status)\n",
    "\n",
    "# Cell 9: Save endpoint information for later use\n",
    "endpoint_info = {\n",
    "    'endpoint_name': endpoint_name,\n",
    "    'region': region,\n",
    "    'model_data': f's3://{bucket_name}/{s3_key}'\n",
    "}\n",
    "\n",
    "print(\"Endpoint information:\")\n",
    "print(endpoint_info)\n",
    "\n",
    "# Cell 10: Create a cleanup function (optional)\n",
    "def cleanup_deployment():\n",
    "    \"\"\"Delete the endpoint and model to avoid ongoing costs\"\"\"\n",
    "    try:\n",
    "        predictor.delete_model()\n",
    "        predictor.delete_endpoint()\n",
    "        print(\"Endpoint and model deleted successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during cleanup: {str(e)}\")\n",
    "\n",
    "# Uncomment the line below if you want to cleanup immediately\n",
    "# cleanup_deployment()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
